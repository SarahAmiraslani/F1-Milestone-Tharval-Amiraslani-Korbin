{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Top 10 Finishers Prediction"]},{"cell_type":"markdown","metadata":{"cell_id":"879f781ac24949eab9c7446156f2cb8c","deepnote_cell_type":"markdown"},"source":["Below are the columns required for the supervised learning model. Columns marked with an asterisk (*) are indices and won't be included in the model input. Columns marked with a hash (#) are labels.\n","\n","- **Index Columns:**\n","  - *RaceId {year-session} `[race_id]`\n","  - *RacerId {firstname-lastname} `[racer_id]`\n","  - *TrackId {circuitname} `[track_id]`\n","\n","- **Feature Columns:**\n","  - Type of track `[is_street]`\n","    - 0 for purpose-built track\n","    - 1 for street track\n","  - Previous year result for racer `[prev_year_pos]` (0 if not available or didn't participate) \n","  - Qualifying position `[qualifying_pos]` \n","  - Qualifying timing:\n","    - Q1 `[q1_timing]` \n","    - Q2 `[q2_timing]` (if racer didn't qualify for Q2, this will be 0) \n","    - Q3 `[q3_timing]` (if racer didn't qualify for Q3, this will be 0) \n","\n","- **Label Column:**\n","  - #Race finish `[race_finish]` "]},{"cell_type":"markdown","metadata":{},"source":["## Imports and Configuration"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["# Suppress warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Standard library imports\n","import sys\n","import os\n","import logging\n","import time\n","import json\n","\n","# Third-party imports\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from joblib import dump, load\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","\n","# User-defined imports\n","module_path = os.path.abspath(os.path.join(\"..\", \"scripts\"))\n","if module_path not in sys.path:\n","    sys.path.append(module_path)\n","\n","from utilities import load_and_process_csv, join_dataframes"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Configure logging\n","logging.basicConfig(\n","    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",")\n","\n","# Constants\n","REQUIRED_COLUMNS = [\"driverId\", \"q1\", \"q2\", \"q3\", \"race_id\"]"]},{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 11435 entries, 0 to 11434\n","Data columns (total 36 columns):\n"," #   Column                   Non-Null Count  Dtype  \n","---  ------                   --------------  -----  \n"," 0   number                   11435 non-null  int64  \n"," 1   position                 11435 non-null  int64  \n"," 2   positionText             11435 non-null  object \n"," 3   points                   11435 non-null  float64\n"," 4   qualifying_pos           11435 non-null  int64  \n"," 5   laps                     11435 non-null  int64  \n"," 6   status                   11435 non-null  object \n"," 7   season_x                 11435 non-null  int64  \n"," 8   round_x                  11435 non-null  int64  \n"," 9   FastestLap               7805 non-null   object \n"," 10  driverId                 11435 non-null  object \n"," 11  code                     9574 non-null   object \n"," 12  driver_wiki_url          11435 non-null  object \n"," 13  givenName                11435 non-null  object \n"," 14  familyName               11435 non-null  object \n"," 15  dateOfBirth              11435 non-null  object \n"," 16  driver_nationality       11435 non-null  object \n"," 17  permanentNumber          6082 non-null   float64\n"," 18  constructorId            11435 non-null  object \n"," 19  constructor_wiki_url     11435 non-null  object \n"," 20  name                     11435 non-null  object \n"," 21  constructor_nationality  11435 non-null  object \n"," 22  millis                   4902 non-null   float64\n"," 23  time_x                   4902 non-null   object \n"," 24  race_id                  11435 non-null  object \n"," 25  season_y                 11435 non-null  int64  \n"," 26  round_y                  11435 non-null  int64  \n"," 27  raceName                 11435 non-null  object \n"," 28  date                     11435 non-null  object \n"," 29  time_y                   7811 non-null   object \n"," 30  circuitId                11435 non-null  object \n"," 31  circuit                  11435 non-null  object \n"," 32  location                 11435 non-null  object \n"," 33  country                  11435 non-null  object \n"," 34  long                     11435 non-null  float64\n"," 35  lat                      11435 non-null  float64\n","dtypes: float64(5), int64(8), object(23)\n","memory usage: 3.1+ MB\n"]},{"data":{"text/plain":["None"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 9623 entries, 0 to 9622\n","Data columns (total 9 columns):\n"," #   Column         Non-Null Count  Dtype \n","---  ------         --------------  ----- \n"," 0   season         9623 non-null   int64 \n"," 1   round          9623 non-null   int64 \n"," 2   driverId       9623 non-null   object\n"," 3   driver         9623 non-null   object\n"," 4   constructorId  9623 non-null   object\n"," 5   q1_timing      9623 non-null   object\n"," 6   q2_timing      9623 non-null   object\n"," 7   q3_timing      9623 non-null   object\n"," 8   race_id        9623 non-null   object\n","dtypes: int64(2), object(7)\n","memory usage: 676.7+ KB\n"]},{"data":{"text/plain":["None"]},"metadata":{},"output_type":"display_data"}],"source":["# Load and process data\n","race_information_filepath = \"../data/raw/Race_Information_1995_2023.csv\"\n","race_results_filepath = \"../data/raw/Race_Results_1995_2023.csv\"\n","qualifying_results_filepath = \"../data/raw/Qualification_Results_1995_2023.csv\"\n","\n","# load data\n","race_information = load_and_process_csv(race_information_filepath, [\"season\", \"round\"])\n","race_results = load_and_process_csv(\n","    race_results_filepath,\n","    [\"season\", \"round\"],\n","    rename_columns={\"grid\": \"qualifying_pos\",\n","                    \"url\": \"driver_wiki_url\",\n","                    \"nationality\": \"driver_nationality\",\n","                    \"url.1\": \"constructor_wiki_url\",\n","                    \"nationality.1\": \"constructor_nationality\"\n","                    },\n",")\n","\n","\n","qualifying_results = load_and_process_csv(\n","    qualifying_results_filepath,\n","    [\"season\", \"round\"],\n","    rename_columns={\"q1\": \"q1_timing\", \"q2\": \"q2_timing\", \"q3\": \"q3_timing\"},\n","    fill_na_value=0,\n",")\n","\n","# join race information with results\n","race_results_information = join_dataframes(race_results, race_information, \"race_id\")\n","\n","# display information\n","display(race_results_information.info())\n","display(qualifying_results.info())"]},{"cell_type":"markdown","metadata":{},"source":["In 2004, F1 started "]},{"cell_type":"code","execution_count":17,"id":"01J2849CG0BGPBN6NKFG92VVED","metadata":{},"outputs":[{"data":{"text/plain":["status\n","Finished         4896\n","+1 Lap           2403\n","+2 Laps           636\n","Collision         518\n","Engine            462\n","                 ... \n","Oil pump            1\n","+12 Laps            1\n","Tyre puncture       1\n","+26 Laps            1\n","+17 Laps            1\n","Name: count, Length: 109, dtype: int64"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["race_results['status'].value_counts()"]},{"cell_type":"code","execution_count":18,"id":"01J283MNHTV3E7YANCHEJ7R9A7","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>number</th>\n","      <th>position</th>\n","      <th>positionText</th>\n","      <th>points</th>\n","      <th>qualifying_pos</th>\n","      <th>laps</th>\n","      <th>status</th>\n","      <th>season</th>\n","      <th>round</th>\n","      <th>FastestLap</th>\n","      <th>...</th>\n","      <th>dateOfBirth</th>\n","      <th>driver_nationality</th>\n","      <th>permanentNumber</th>\n","      <th>constructorId</th>\n","      <th>constructor_wiki_url</th>\n","      <th>name</th>\n","      <th>constructor_nationality</th>\n","      <th>millis</th>\n","      <th>time</th>\n","      <th>race_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>10.0</td>\n","      <td>2</td>\n","      <td>71</td>\n","      <td>Finished</td>\n","      <td>1995</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>1969-01-03</td>\n","      <td>German</td>\n","      <td>NaN</td>\n","      <td>benetton</td>\n","      <td>http://en.wikipedia.org/wiki/Benetton_Formula</td>\n","      <td>Benetton</td>\n","      <td>Italian</td>\n","      <td>5914154.0</td>\n","      <td>1:38:34.154</td>\n","      <td>1995_1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>6.0</td>\n","      <td>3</td>\n","      <td>71</td>\n","      <td>Finished</td>\n","      <td>1995</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>1971-03-27</td>\n","      <td>British</td>\n","      <td>NaN</td>\n","      <td>williams</td>\n","      <td>http://en.wikipedia.org/wiki/Williams_Grand_Pr...</td>\n","      <td>Williams</td>\n","      <td>British</td>\n","      <td>5925214.0</td>\n","      <td>+11.060</td>\n","      <td>1995_1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>4.0</td>\n","      <td>5</td>\n","      <td>70</td>\n","      <td>+1 Lap</td>\n","      <td>1995</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>1959-08-27</td>\n","      <td>Austrian</td>\n","      <td>NaN</td>\n","      <td>ferrari</td>\n","      <td>http://en.wikipedia.org/wiki/Scuderia_Ferrari</td>\n","      <td>Ferrari</td>\n","      <td>Italian</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1995_1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>3.0</td>\n","      <td>7</td>\n","      <td>70</td>\n","      <td>+1 Lap</td>\n","      <td>1995</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>1968-09-28</td>\n","      <td>Finnish</td>\n","      <td>NaN</td>\n","      <td>mclaren</td>\n","      <td>http://en.wikipedia.org/wiki/McLaren</td>\n","      <td>McLaren</td>\n","      <td>British</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1995_1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>27</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2.0</td>\n","      <td>6</td>\n","      <td>70</td>\n","      <td>+1 Lap</td>\n","      <td>1995</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>1964-06-11</td>\n","      <td>French</td>\n","      <td>NaN</td>\n","      <td>ferrari</td>\n","      <td>http://en.wikipedia.org/wiki/Scuderia_Ferrari</td>\n","      <td>Ferrari</td>\n","      <td>Italian</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1995_1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>11430</th>\n","      <td>2</td>\n","      <td>16</td>\n","      <td>16</td>\n","      <td>0.0</td>\n","      <td>20</td>\n","      <td>58</td>\n","      <td>Finished</td>\n","      <td>2023</td>\n","      <td>22</td>\n","      <td>{'rank': '12', 'lap': '43', 'Time': {'time': '...</td>\n","      <td>...</td>\n","      <td>2000-12-31</td>\n","      <td>American</td>\n","      <td>2.0</td>\n","      <td>williams</td>\n","      <td>http://en.wikipedia.org/wiki/Williams_Grand_Pr...</td>\n","      <td>Williams</td>\n","      <td>British</td>\n","      <td>5310415.0</td>\n","      <td>+1:27.791</td>\n","      <td>2023_22</td>\n","    </tr>\n","    <tr>\n","      <th>11431</th>\n","      <td>24</td>\n","      <td>17</td>\n","      <td>17</td>\n","      <td>0.0</td>\n","      <td>19</td>\n","      <td>58</td>\n","      <td>Finished</td>\n","      <td>2023</td>\n","      <td>22</td>\n","      <td>{'rank': '13', 'lap': '43', 'Time': {'time': '...</td>\n","      <td>...</td>\n","      <td>1999-05-30</td>\n","      <td>Chinese</td>\n","      <td>24.0</td>\n","      <td>alfa</td>\n","      <td>http://en.wikipedia.org/wiki/Alfa_Romeo_in_For...</td>\n","      <td>Alfa Romeo</td>\n","      <td>Swiss</td>\n","      <td>5312046.0</td>\n","      <td>+1:29.422</td>\n","      <td>2023_22</td>\n","    </tr>\n","    <tr>\n","      <th>11432</th>\n","      <td>55</td>\n","      <td>18</td>\n","      <td>18</td>\n","      <td>0.0</td>\n","      <td>16</td>\n","      <td>57</td>\n","      <td>Retired</td>\n","      <td>2023</td>\n","      <td>22</td>\n","      <td>{'rank': '17', 'lap': '42', 'Time': {'time': '...</td>\n","      <td>...</td>\n","      <td>1994-09-01</td>\n","      <td>Spanish</td>\n","      <td>55.0</td>\n","      <td>ferrari</td>\n","      <td>http://en.wikipedia.org/wiki/Scuderia_Ferrari</td>\n","      <td>Ferrari</td>\n","      <td>Italian</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2023_22</td>\n","    </tr>\n","    <tr>\n","      <th>11433</th>\n","      <td>77</td>\n","      <td>19</td>\n","      <td>19</td>\n","      <td>0.0</td>\n","      <td>18</td>\n","      <td>57</td>\n","      <td>+1 Lap</td>\n","      <td>2023</td>\n","      <td>22</td>\n","      <td>{'rank': '18', 'lap': '42', 'Time': {'time': '...</td>\n","      <td>...</td>\n","      <td>1989-08-28</td>\n","      <td>Finnish</td>\n","      <td>77.0</td>\n","      <td>alfa</td>\n","      <td>http://en.wikipedia.org/wiki/Alfa_Romeo_in_For...</td>\n","      <td>Alfa Romeo</td>\n","      <td>Swiss</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2023_22</td>\n","    </tr>\n","    <tr>\n","      <th>11434</th>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0.0</td>\n","      <td>17</td>\n","      <td>57</td>\n","      <td>+1 Lap</td>\n","      <td>2023</td>\n","      <td>22</td>\n","      <td>{'rank': '19', 'lap': '46', 'Time': {'time': '...</td>\n","      <td>...</td>\n","      <td>1992-10-05</td>\n","      <td>Danish</td>\n","      <td>20.0</td>\n","      <td>haas</td>\n","      <td>http://en.wikipedia.org/wiki/Haas_F1_Team</td>\n","      <td>Haas F1 Team</td>\n","      <td>American</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2023_22</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>11435 rows × 25 columns</p>\n","</div>"],"text/plain":["       number  position positionText  points  qualifying_pos  laps    status  \\\n","0           1         1            1    10.0               2    71  Finished   \n","1           6         2            2     6.0               3    71  Finished   \n","2          28         3            3     4.0               5    70    +1 Lap   \n","3           8         4            4     3.0               7    70    +1 Lap   \n","4          27         5            5     2.0               6    70    +1 Lap   \n","...       ...       ...          ...     ...             ...   ...       ...   \n","11430       2        16           16     0.0              20    58  Finished   \n","11431      24        17           17     0.0              19    58  Finished   \n","11432      55        18           18     0.0              16    57   Retired   \n","11433      77        19           19     0.0              18    57    +1 Lap   \n","11434      20        20           20     0.0              17    57    +1 Lap   \n","\n","       season  round                                         FastestLap  ...  \\\n","0        1995      1                                                NaN  ...   \n","1        1995      1                                                NaN  ...   \n","2        1995      1                                                NaN  ...   \n","3        1995      1                                                NaN  ...   \n","4        1995      1                                                NaN  ...   \n","...       ...    ...                                                ...  ...   \n","11430    2023     22  {'rank': '12', 'lap': '43', 'Time': {'time': '...  ...   \n","11431    2023     22  {'rank': '13', 'lap': '43', 'Time': {'time': '...  ...   \n","11432    2023     22  {'rank': '17', 'lap': '42', 'Time': {'time': '...  ...   \n","11433    2023     22  {'rank': '18', 'lap': '42', 'Time': {'time': '...  ...   \n","11434    2023     22  {'rank': '19', 'lap': '46', 'Time': {'time': '...  ...   \n","\n","      dateOfBirth driver_nationality permanentNumber constructorId  \\\n","0      1969-01-03             German             NaN      benetton   \n","1      1971-03-27            British             NaN      williams   \n","2      1959-08-27           Austrian             NaN       ferrari   \n","3      1968-09-28            Finnish             NaN       mclaren   \n","4      1964-06-11             French             NaN       ferrari   \n","...           ...                ...             ...           ...   \n","11430  2000-12-31           American             2.0      williams   \n","11431  1999-05-30            Chinese            24.0          alfa   \n","11432  1994-09-01            Spanish            55.0       ferrari   \n","11433  1989-08-28            Finnish            77.0          alfa   \n","11434  1992-10-05             Danish            20.0          haas   \n","\n","                                    constructor_wiki_url          name  \\\n","0          http://en.wikipedia.org/wiki/Benetton_Formula      Benetton   \n","1      http://en.wikipedia.org/wiki/Williams_Grand_Pr...      Williams   \n","2          http://en.wikipedia.org/wiki/Scuderia_Ferrari       Ferrari   \n","3                   http://en.wikipedia.org/wiki/McLaren       McLaren   \n","4          http://en.wikipedia.org/wiki/Scuderia_Ferrari       Ferrari   \n","...                                                  ...           ...   \n","11430  http://en.wikipedia.org/wiki/Williams_Grand_Pr...      Williams   \n","11431  http://en.wikipedia.org/wiki/Alfa_Romeo_in_For...    Alfa Romeo   \n","11432      http://en.wikipedia.org/wiki/Scuderia_Ferrari       Ferrari   \n","11433  http://en.wikipedia.org/wiki/Alfa_Romeo_in_For...    Alfa Romeo   \n","11434          http://en.wikipedia.org/wiki/Haas_F1_Team  Haas F1 Team   \n","\n","      constructor_nationality     millis         time  race_id  \n","0                     Italian  5914154.0  1:38:34.154   1995_1  \n","1                     British  5925214.0      +11.060   1995_1  \n","2                     Italian        NaN          NaN   1995_1  \n","3                     British        NaN          NaN   1995_1  \n","4                     Italian        NaN          NaN   1995_1  \n","...                       ...        ...          ...      ...  \n","11430                 British  5310415.0    +1:27.791  2023_22  \n","11431                   Swiss  5312046.0    +1:29.422  2023_22  \n","11432                 Italian        NaN          NaN  2023_22  \n","11433                   Swiss        NaN          NaN  2023_22  \n","11434                American        NaN          NaN  2023_22  \n","\n","[11435 rows x 25 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["race_results"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"69efb3c3903d4317ae6c770b3189643b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":491,"execution_start":1709433641275,"source_hash":null},"outputs":[],"source":["# Assuming you want to keep all matches and all columns from both DataFrames are relevant\n","merged_df = pd.merge(\n","    REQUIRED_COLUMNS,\n","    race_results_information[\n","        [\n","            \"driverId\",\n","            \"race_id\",\n","            \"position\",\n","            \"qualifying_pos\",\n","            \"prev_year_pos\",\n","            \"season\",\n","            \"round\",\n","        ]\n","    ],\n","    on=[\"driverId\", \"race_id\"],\n","    how=\"inner\",\n","    validate=\"one_to_one\",\n",")\n","\n","# Directly saving the required DataFrame to CSV, no need to create an intermediate DataFrame\n","merged_df.to_csv(\"../data/prepared/Complete_data_supervised_learning.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"2e0432a140b743a9a5ad77a184261273","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":92,"execution_start":1709587347198,"source_hash":null},"outputs":[],"source":["# You can also read the data directly (if available)\n","final_data = pd.read_csv(\"Complete_data_supervised_learning.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"3825cd3b4c7e4dbf920e72f318829395","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":58,"execution_start":1709587348444,"source_hash":null},"outputs":[],"source":["# Convert timing columns to seconds\n","final_data['q1_timing'] = final_data['q1_timing'].apply(convert_to_seconds)\n","final_data['q2_timing'] = final_data['q2_timing'].apply(convert_to_seconds)\n","final_data['q3_timing'] = final_data['q3_timing'].apply(convert_to_seconds)\n","final_data['position'] = final_data['position'].apply(lambda x: 1 if x <= 10 else 0)\n","final_data_required = final_data[[\"q1_timing\", \"q2_timing\", \"q3_timing\", \"qualifying_pos\", \"prev_year_pos\", \"position\"]]\n","final_data_scaled = final_data_required.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"f20e54288900417b9c9803bb8c0e8755","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":431,"execution_start":1709587356712,"source_hash":null},"outputs":[],"source":["scaler = MinMaxScaler()\n","final_data_scaled[['q1_timing', 'q2_timing', 'q3_timing', 'qualifying_pos', 'prev_year_pos']] = scaler.fit_transform(final_data_scaled[['q1_timing', 'q2_timing', 'q3_timing', 'qualifying_pos', 'prev_year_pos']])\n","\n","# Calculate correlation matrix\n","corr_matrix = final_data_scaled.corr()\n","\n","# Plotting the correlation matrix as a heatmap\n","plt.figure(figsize=(20, 10))\n","sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"bf2ef54aa3f34c16bac5bab6619ccee2","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":292,"execution_start":1709587362138,"source_hash":null},"outputs":[],"source":["# Splitting the dataset into features and the label\n","label_col = \"position\"\n","X = final_data_required.drop(label_col, axis=1)\n","y = final_data_required[label_col]\n","\n","# Splitting the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Normalizing the feature data\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["## Modeling"]},{"cell_type":"markdown","metadata":{},"source":["### Linear Methods"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def build_best_logistic_regression_model(\n","    X_train_scaled, X_test_scaled, y_train, y_test, param_grid, **grid_search_kwargs\n","):\n","    \"\"\"\n","    Builds and returns the best Logistic Regression model using GridSearchCV.\n","\n","    Args:\n","        X_train_scaled (pd.DataFrame): Scaled training features.\n","        X_test_scaled (pd.DataFrame): Scaled test features.\n","        y_train (pd.Series): Training labels.\n","        y_test (pd.Series): Test labels.\n","        param_grid (dict): Parameter grid for GridSearchCV.\n","        **grid_search_kwargs: Additional keyword arguments for GridSearchCV.\n","\n","    Returns:\n","        best_model (LogisticRegression): The best Logistic Regression model.\n","        accuracy (float): Accuracy of the best model on the test set.\n","    \"\"\"\n","    # Initializing the Logistic Regression model\n","    log_reg = LogisticRegression(random_state=42, max_iter=1000)\n","\n","    # Setting up GridSearchCV to find the best model\n","    grid_search = GridSearchCV(\n","        estimator=log_reg,\n","        param_grid=param_grid,\n","        cv=5,\n","        scoring=\"accuracy\",\n","        n_jobs=-1,\n","        verbose=1,\n","        **grid_search_kwargs,\n","    )\n","\n","    start_time = time.time()\n","    logging.info(\"Starting GridSearchCV to find the best Logistic Regression model.\")\n","\n","    try:\n","        # Fitting GridSearchCV to the training data\n","        grid_search.fit(X_train_scaled, y_train)\n","\n","        # Extracting the best estimator (model)\n","        best_model = grid_search.best_estimator_\n","\n","        # Making predictions with the best model on the test set\n","        y_pred = best_model.predict(X_test_scaled)\n","\n","        # Calculating the accuracy of the best model\n","        accuracy = accuracy_score(y_test, y_pred)\n","\n","        end_time = time.time()\n","        elapsed_time = end_time - start_time\n","\n","        logging.info(f\"GridSearchCV completed in {elapsed_time:.2f} seconds.\")\n","        logging.info(f\"Best Model's Accuracy: {accuracy * 100:.2f}%\")\n","        logging.info(f\"Best Parameters: {grid_search.best_params_}\")\n","\n","        # Returning the best model and its accuracy\n","        return best_model, accuracy\n","\n","    except Exception as e:\n","        logging.error(f\"An error occurred during GridSearchCV: {e}\")\n","        return None, None\n","\n","\n","# Defining the parameter grid for logistic regression\n","lr_param_grid = {\n","    \"C\": [0.01, 0.1, 1, 10, 100],\n","    \"penalty\": [\"l1\", \"l2\"],\n","    \"solver\": [\"liblinear\"],  # 'liblinear' is compatible with l1 and l2 penalties.\n","}\n","\n","# Building and evaluating the Logistic Regression model\n","best_lr_model, best_lr_accuracy = build_best_logistic_regression_model(\n","    X_train_scaled,\n","    X_test_scaled,\n","    y_train,\n","    y_test,\n","    lr_param_grid,\n","    return_train_score=True,\n",")\n","\n","if best_lr_model is not None:\n","    dump(best_lr_model, \"best_logistic_regression_model.joblib\")\n","    # You can also read the model directly if available\n","    # best_lr_model = load(\"best_logistic_regression_model.joblib\")"]},{"cell_type":"markdown","metadata":{},"source":["### Ensemble Methods"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"aefab90c280645d3ad1794f9bd986d86","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":141196,"execution_start":1709587488247,"source_hash":null},"outputs":[],"source":["def build_best_random_forest_model(\n","    X_train, X_test, y_train, y_test, param_grid, **grid_search_kwargs\n","):\n","    \"\"\"\n","    Builds and returns the best Random Forest model using GridSearchCV.\n","\n","    Args:\n","        X_train (pd.DataFrame): Training features.\n","        X_test (pd.DataFrame): Test features.\n","        y_train (pd.Series): Training labels.\n","        y_test (pd.Series): Test labels.\n","        param_grid (dict): Parameter grid for GridSearchCV.\n","        **grid_search_kwargs: Additional keyword arguments for GridSearchCV.\n","\n","    Returns:\n","        best_model (RandomForestClassifier): The best Random Forest model.\n","        accuracy (float): Accuracy of the best model on the test set.\n","    \"\"\"\n","    # Initializing the Random Forest classifier\n","    rf_clf = RandomForestClassifier(random_state=42)\n","\n","    # Setting up GridSearchCV to find the best model\n","    grid_search = GridSearchCV(\n","        estimator=rf_clf,\n","        param_grid=param_grid,\n","        cv=5,\n","        scoring=\"accuracy\",\n","        n_jobs=-1,\n","        verbose=1,\n","        **grid_search_kwargs,\n","    )\n","\n","    start_time = time.time()\n","    logging.info(\"Starting GridSearchCV to find the best Random Forest model.\")\n","\n","    try:\n","        # Fitting GridSearchCV to the training data\n","        grid_search.fit(X_train, y_train)\n","\n","        # Extracting the best estimator (model)\n","        best_model = grid_search.best_estimator_\n","\n","        # Making predictions with the best model on the test set\n","        y_pred = best_model.predict(X_test)\n","\n","        # Calculating the accuracy of the best model\n","        accuracy = accuracy_score(y_test, y_pred)\n","\n","        end_time = time.time()\n","        elapsed_time = end_time - start_time\n","\n","        logging.info(f\"GridSearchCV completed in {elapsed_time:.2f} seconds.\")\n","        logging.info(f\"Best Model's Accuracy: {accuracy * 100:.2f}%\")\n","        logging.info(f\"Best Parameters: {grid_search.best_params_}\")\n","\n","        # Returning the best model and its accuracy\n","        return best_model, accuracy\n","\n","    except Exception as e:\n","        logging.error(f\"An error occurred during GridSearchCV: {e}\")\n","        return None, None\n","\n","\n","# Defining the parameter grid for Random Forest\n","rf_param_grid = {\n","    \"n_estimators\": [10, 50, 100, 200],\n","    \"max_depth\": [None, 10, 20, 30],\n","    \"min_samples_split\": [2, 5, 10],\n","}\n","\n","# Example usage with additional GridSearchCV parameters\n","best_rf_model, best_rf_accuracy = build_best_random_forest_model(\n","    X_train_scaled,\n","    X_test_scaled,\n","    y_train,\n","    y_test,\n","    rf_param_grid,\n","    return_train_score=True,\n",")\n","\n","if best_rf_model is not None:\n","    dump(best_rf_model, \"best_random_forest_model.joblib\")\n","\n","    # You can also read the model directly if available\n","    # best_rf_model = load(\"../models/best_random_forest_model.joblib\")"]},{"cell_type":"markdown","metadata":{},"source":["### Neural Network Methods"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"0b999aa56fee47449f662c7d3266416b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":594487,"execution_start":1709587629885,"source_hash":null},"outputs":[],"source":["def create_model(hidden_nodes=1, learning_rate=0.001):\n","    \"\"\"\n","    Creates and compiles a Keras Sequential model.\n","\n","    Args:\n","        hidden_nodes (int): Number of nodes in the hidden layer.\n","        learning_rate (float): Learning rate for the optimizer.\n","\n","    Returns:\n","        model (Sequential): Compiled Keras model.\n","    \"\"\"\n","    # Define the model\n","    model = Sequential()\n","    model.add(Dense(hidden_nodes, input_dim=X_train_scaled.shape[1], activation=\"relu\"))\n","    model.add(Dense(1, activation=\"sigmoid\"))  # Output layer for binary classification\n","\n","    # Compile the model\n","    optimizer = Adam(learning_rate=learning_rate)\n","    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n","    return model\n","\n","\n","def build_best_neural_network_model(\n","    X_train_scaled, X_test_scaled, y_train, y_test, param_grid, **grid_search_kwargs\n","):\n","    \"\"\"\n","    Builds and returns the best neural network model using GridSearchCV.\n","\n","    Args:\n","        X_train_scaled (pd.DataFrame): Scaled training features.\n","        X_test_scaled (pd.DataFrame): Scaled test features.\n","        y_train (pd.Series): Training labels.\n","        y_test (pd.Series): Test labels.\n","        param_grid (dict): Parameter grid for GridSearchCV.\n","        **grid_search_kwargs: Additional keyword arguments for GridSearchCV.\n","\n","    Returns:\n","        best_model (KerasClassifier): The best neural network model.\n","        accuracy (float): Accuracy of the best model on the test set.\n","    \"\"\"\n","    # Wrapping the Keras model so it can be used by scikit-learn\n","    model = KerasClassifier(build_fn=create_model, verbose=0)\n","\n","    # Setting up GridSearchCV to find the best model\n","    grid_search = GridSearchCV(\n","        estimator=model,\n","        param_grid=param_grid,\n","        cv=5,\n","        scoring=\"accuracy\",\n","        n_jobs=-1,\n","        verbose=1,\n","        **grid_search_kwargs,\n","    )\n","\n","    start_time = time.time()\n","    logging.info(\"Starting GridSearchCV to find the best neural network model.\")\n","\n","    try:\n","        # Fitting GridSearchCV to the training data\n","        grid_search.fit(X_train_scaled, y_train)\n","\n","        # Extracting the best estimator (model)\n","        best_model = grid_search.best_estimator_\n","\n","        # Making predictions with the best model on the test set\n","        y_pred = best_model.predict(X_test_scaled)\n","        y_pred = np.round(y_pred).astype(int)  # Convert probabilities to binary output\n","\n","        # Calculating the accuracy of the best model\n","        accuracy = accuracy_score(y_test, y_pred)\n","\n","        end_time = time.time()\n","        elapsed_time = end_time - start_time\n","\n","        logging.info(f\"GridSearchCV completed in {elapsed_time:.2f} seconds.\")\n","        logging.info(f\"Best Model's Accuracy: {accuracy * 100:.2f}%\")\n","        logging.info(f\"Best Parameters: {grid_search.best_params_}\")\n","\n","        # Returning the best model and its accuracy\n","        return best_model, accuracy\n","\n","    except Exception as e:\n","        logging.error(f\"An error occurred during GridSearchCV: {e}\")\n","        return None, None\n","\n","\n","# Defining the parameter grid for the neural network\n","nn_param_grid = {\n","    \"hidden_nodes\": [10, 50, 100],\n","    \"learning_rate\": [0.001, 0.01, 0.1],\n","    \"epochs\": [50],\n","    \"batch_size\": [32],\n","}\n","\n","# Building and evaluating the neural network model\n","best_nn_model, best_nn_accuracy = build_best_neural_network_model(\n","    X_train_scaled,\n","    X_test_scaled,\n","    y_train,\n","    y_test,\n","    nn_param_grid,\n","    return_train_score=True,\n",")\n","\n","if best_nn_model is not None:\n","    dump(best_nn_model, \"best_neural_network_model.joblib\")\n","\n","    # You can also read the model directly if available\n","    # best_nn_model = load(\"../models/best_neural_network_model.joblib\")"]},{"cell_type":"markdown","metadata":{},"source":["### Model Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"6b49e893c4534bdd88d04adcd70f0e64","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":97327,"execution_start":1709588835781,"source_hash":null},"outputs":[],"source":["def perform_sensitivity_analysis(\n","    models, X_scaled, feature_names, output_dir=\".\", file_format=\"png\"\n","):\n","    \"\"\"\n","    Perform sensitivity analysis on given models.\n","\n","    Args:\n","        models (dict): Dictionary of trained models with their names as keys.\n","        X_scaled (np.ndarray): Scaled features array.\n","        feature_names (list): List of feature names.\n","        output_dir (str): Directory to save the sensitivity analysis plots.\n","        file_format (str): File format for saving plots.\n","    \"\"\"\n","    # Number of points to evaluate for each feature\n","    num_points = 100\n","\n","    # Results dictionary to store sensitivity data\n","    sensitivity_results = {}\n","\n","    # Iterate through each model\n","    for model_name, model in models.items():\n","        logging.info(f\"Analyzing model: {model_name}\")\n","        sensitivity_results[model_name] = {}\n","\n","        # Iterate through each feature\n","        for feature in feature_names:\n","            # Array to hold predictions\n","            predictions = []\n","\n","            # Generate values across the range\n","            feature_index = feature_names.index(feature)\n","            min_val, max_val = np.min(X_scaled[:, feature_index]), np.max(\n","                X_scaled[:, feature_index]\n","            )\n","            values = np.linspace(min_val, max_val, num_points)\n","\n","            # Modify one feature at a time, keeping others constant\n","            for val in values:\n","                X_temp = np.copy(X_scaled)\n","                X_temp[:, feature_index] = val\n","                try:\n","                    pred = model.predict(X_temp)\n","                    predictions.append(np.mean(pred))\n","                except Exception as e:\n","                    logging.error(\n","                        f\"Error predicting with model {model_name} for feature {feature}: {e}\"\n","                    )\n","                    predictions.append(np.nan)  # Use NaN to indicate prediction failure\n","\n","            sensitivity_results[model_name][feature] = np.nanstd(\n","                predictions\n","            )  # Use nanstd to handle NaNs\n","\n","    # Plotting the sensitivity results\n","    for model_name, sensitivities in sensitivity_results.items():\n","        plt.figure(figsize=(10, 6))\n","        plt.title(f\"Sensitivity Analysis for {model_name}\")\n","        plt.bar(range(len(sensitivities)), list(sensitivities.values()), align=\"center\")\n","        plt.xticks(\n","            range(len(sensitivities)), list(sensitivities.keys()), rotation=\"vertical\"\n","        )\n","        plt.ylabel(\"Standard Deviation of Predictions\")\n","\n","        file_path = f\"{output_dir}/sensitivity_{model_name}.{file_format}\"\n","        plt.savefig(file_path, dpi=300)\n","        plt.show()\n","        logging.info(f\"Sensitivity plot saved to {file_path}\")\n","\n","\n","# Example usage\n","models = {\n","    \"Random Forest\": best_rf_model,\n","    \"Logistic Regression\": best_lr_model,\n","    \"Neural Network\": best_nn_model,\n","}\n","\n","feature_names = [\n","    \"q1_timing\",\n","    \"q2_timing\",\n","    \"q3_timing\",\n","    \"qualifying_pos\",\n","    \"prev_year_pos\",\n","]\n","perform_sensitivity_analysis(models, X_test_scaled, feature_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"f90ac10364f649cbba5c6fc8f1480307","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":30395,"execution_start":1709435171245,"source_hash":null},"outputs":[],"source":["# Assuming final_data_required is your DataFrame\n","sns.pairplot(final_data_required, hue='position')\n","plt.savefig('pairplot.png', dpi=300)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Visualizations"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"fe04c53a9033421ca1b562892325700f","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1480,"execution_start":1709434729867,"source_hash":null},"outputs":[],"source":["\n","# Assuming X_train and y_train are already defined\n","rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf.fit(X_train_scaled, y_train)\n","\n","# Getting feature importances\n","feature_importances = rf.feature_importances_\n","\n","# Converting to a DataFrame for easier plotting\n","importances_df = pd.DataFrame({'feature': X_train.columns, 'importance': feature_importances})\n","\n","# Sorting by importance\n","importances_df = importances_df.sort_values('importance', ascending=False)\n","\n","# Plotting\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x='importance', y='feature', data=importances_df)\n","plt.title('Feature Importance')\n","plt.xlabel('Importance')\n","plt.ylabel('Feature')\n","plt.show()"]}],"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"f8ecb97b6e994a008c3f46001ea4d527","deepnote_persisted_session":{"createdAt":"2024-03-04T22:49:48.106Z"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}
